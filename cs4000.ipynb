{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286ea073-f47c-40f6-83dd-94ff4f52f3a6",
   "metadata": {},
   "source": [
    "![CS 4000](images/cs4000-title.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f332b-43c6-481e-af62-d292ef3a11e0",
   "metadata": {},
   "source": [
    "## **Course Description:**\n",
    "\n",
    "\n",
    "CS 4000 - Intro to Distributed, Parallel, and Web-Centric Computing is one of the most interesting courses in the CS core cirriculum here at Ohio University. In this course you will learn about several interesting topics involving parallel and distributed computing like threading, synchronization, and potential speedup of programs. CS 4000 is a very project-based course so throughout the semester you will get plenty of hands-on learning involving the topics you will eventually learn about in lecture. Because you will be developing parallel and distributed programs on your own in this course, another essential topic you will learn about is how to calculate and optimize the efficency of your programs. Developing and optimizing programs to be as efficient as possible is a key skill you will develop in this course. Altogether, this course will definetly make you think about optimization more than you ever have before, and allow you to utilize the hardware behind the scenes to create lightning fast programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483e5e4-3dd3-471c-9eab-d204fc5cc01d",
   "metadata": {},
   "source": [
    "## **Course Topics:**\n",
    "1. <u>Basic Terminology and Concepts</u> <br>\n",
    "    Parallel vs. Distributed vs. Concurrent vs. Web-Centric Computing; Sequential and Parallel Models of Computation (Turing Machine and RAM vs. PRAM, Boolean Circuits); Introduction to Networking <br>\n",
    "2. <u>Parallel Algorithmic Techniques</u> <br>\n",
    "    Divide and Conquer; Parallel Prefix Computation; Map/Reduce; Cache Oblivious and Communication Avoiding Algorithms <br>\n",
    "3. <u>Parallel/Distributed Performance (Amdahl’s Law and Gustafson’s Law)</u> <br>\n",
    "4. <u>Data Dependencies and Critical Paths</u> <br>\n",
    "5. <u>Threading, Synchronization, and Multi-Core Programming</u> <br>\n",
    "    Race conditions; Critical sections; OpenMP; PThreads <br>\n",
    "6. <u>Distributed and Cluster Computing</u> <br>\n",
    "    OpenMPI; Hadoop / Spark; Sockets and Client Server Programming; Related Security Issues. <br>\n",
    "7. <u>Advanced Topics/ Web Centric Computing</u> <br>\n",
    "    Web-Centric Computing/Web Services, Web-Programming Languages; Web-Security Issues <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5200a5-b7ef-4c15-b3c5-7aaea2421f86",
   "metadata": {},
   "source": [
    "## **Examples of What You'll Learn:**\n",
    "\n",
    "For this class, we are going to show you one way of developing a parallel program in C++ using a built-in library called C++ Threads. From there we are going to cover how we can calculate the efficiency of the parallel program, and also calculate the potential speed-up. However, speed-up has certain limitations - as described with Amdahl’s Law and Gustafson’s Law."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6454f746-0e84-45ca-946a-b605e888cac4",
   "metadata": {},
   "source": [
    "### **Parallel Programming with C++ Threads** \n",
    "\n",
    "C++ threads are a built-in library in the C++ language that supports multi-platform shared-memory multithreading programming in C++. What this technically means is that we can use functionality from the C++ Threads library to create C++ programs that run in parallel. A program that runs in parallel utilizes multiple computer processesors to simoultaneously carry out the calculations of a program. Instead of a normal program that only uses one of your computer's processors, a parallel program can use several at the same time! We can use C++ Threads to develop our C++ programs, and the program will tell the machine the program is running on to run it in parallel using multiple threads. Checkout the example below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b73038-2630-4535-9ff9-216861702cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <thread>\n",
    "\n",
    "void call_from_thread(int tid) {\n",
    "    std::cout << \"Launched by thread \" << tid << std::endl;\n",
    "}\n",
    "static const int num_threads = 10;\n",
    "std::thread t[num_threads];\n",
    "\n",
    "//Launch a group of threads\n",
    "for (int i = 0; i < num_threads; ++i) {\n",
    "    t[i] = std::thread(call_from_thread, i);\n",
    "}\n",
    "\n",
    "//Join the threads with the main thread\n",
    "for (int i = 0; i < num_threads; ++i) {\n",
    "    t[i].join();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c7284-67d9-4ab2-92a6-d2360dccf435",
   "metadata": {},
   "source": [
    "If you run the above code block multiple times, you will see that the order in which each thread executes varies every time. This is because the threads are pretty unpredictable in this way. If you were to go further and break up a set of computations or calcluations, you could assign a specific set of those computations to certain threads and bring them altogether at the end to make the program execute the computations in parallel. The beauty behind this dynamic of parallelism is breaking up work into sections or 'threads', so they can execute at the same time and ultimatley speed up the program by a substantial amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f7fe0-9475-48a4-98b2-17e5eaa05b51",
   "metadata": {},
   "source": [
    "### **Speed-Up and Efficiency**\n",
    "\n",
    "In this class, you'll be asked to write parallel programs in C++ that achieve a certain efficiency. A well written parallel program is considered to be about 75% efficient.\n",
    "\n",
    "Speedup of a parallel program is defined to be, **S = Time of sequential / Time of parallel**. That is, the ratio of the time taken by the original program and the time taken by the parallel version. This number, in general, should be bounded by the number of processors on the system.\n",
    "\n",
    "The efficiency of the parallel execution is **E = S / p, where S is the speedup, and where p is the number of processors being used.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf0cf88-a560-4406-8582-0564eee3338d",
   "metadata": {},
   "source": [
    "\n",
    "#### **Speed-up Question #1: Compute the following value:**\n",
    "\n",
    "Parallel time = 25 seconds, sequential time = 2 minutes 15 seconds.  What is the speedup of your parallel code? \n",
    "\n",
    "Check your answer by running the code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcec1a0-9d6b-4385-9085-44d44bd4bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "double parallel_time = 25;\n",
    "double sequential_time = 135;\n",
    "int num_of_processors = 1;\n",
    "double speedup = sequential_time / parallel_time;\n",
    "double efficiency = speedup / num_of_processors;\n",
    "\n",
    "printf(\"Answer: Speedup = %.2f\",speedup);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0edbe-d40b-49ab-9a3a-5620d0205182",
   "metadata": {},
   "source": [
    "\t\n",
    "#### **Speed-up Question #2: Compute the following value:**\n",
    "\n",
    "Parallel time = 20 seconds, sequential time = 4 minutes 20 seconds.  What is the speedup of your parallel code? \n",
    "\n",
    "Run the code below to check yours answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66c064-8b9d-41e0-8ec9-fae2a4a9a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "double parallel_time = 20;\n",
    "double sequential_time = 260;\n",
    "int num_of_processors = 1;\n",
    "double speedup = sequential_time / parallel_time;\n",
    "double efficiency = speedup / num_of_processors;\n",
    "\n",
    "printf(\"Answer: Speedup = %.2f\",speedup);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd534263-7f51-4200-a110-0b2a6bd769e1",
   "metadata": {},
   "source": [
    "#### **Efficieny Question #1: Compute the following value:**\n",
    "\n",
    "Parallel time = 20 seconds, sequential time = 2 minutes 15 seconds.  Number of processors = 8.  What is the efficiency of your parallel code?\n",
    "\n",
    "Run the code below to check your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36563ae7-0780-4699-a203-ef514754b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "double parallel_time = 20;\n",
    "double sequential_time = 135;\n",
    "int num_of_processors = 8;\n",
    "double speedup = sequential_time / parallel_time;\n",
    "double efficiency = speedup / num_of_processors;\n",
    "\n",
    "printf(\"Answer: Speedup = %.2f\",speedup);\n",
    "printf(\"\\n\");\n",
    "printf(\"Answer: Efficiency = %.2f, or %.2f%%\",efficiency,efficiency * 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5273612-7e31-4934-8355-634adf92b564",
   "metadata": {},
   "source": [
    "#### **Efficieny Question #2: Compute the following value:**\n",
    "\n",
    "Parallel time = 20 seconds, sequential time = 4 minutes 20 seconds.  Number of processors = 16.  What is the efficiency of your parallel code?\n",
    "\n",
    "Run the code below to check your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7df4f8-defb-4bf0-9964-27acc77d71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "double parallel_time = 20;\n",
    "double sequential_time = 260;\n",
    "int num_of_processors = 16;\n",
    "double speedup = sequential_time / parallel_time;\n",
    "double efficiency = speedup / num_of_processors;\n",
    "\n",
    "printf(\"Answer: Speedup = %.2f\",speedup);\n",
    "printf(\"\\n\");\n",
    "printf(\"Answer: Efficiency = %.2f, or %.2f%%\",efficiency,efficiency * 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e8fe5-a09c-4638-a963-dc7d78c76b90",
   "metadata": {},
   "source": [
    "### **Amdahl’s Law and Gustafson’s Law**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa07c84-9d78-4dac-aaba-eae46f306a5b",
   "metadata": {},
   "source": [
    "#### Amdahls Law:\n",
    "\n",
    "Gene Amdahl in the 1960’s observed that, in any software system, part of that system must be executed sequentially due to dependency constraints, while other parts of a system may be executed in parallel. Amdahl suggested a simple model where some percentage (S) of a software system must be executed sequentially. In those cases, the value of S limits the performance enhancements that can be made when applying multiple processors to the same system.\n",
    "\n",
    "According to Amdahls Law, the maximum speedup using N processors that can be achieved when S percent of a software system must be executed sequentially is: \n",
    "\n",
    "**Maximum Speedup = 1 / ( S + (1 - S) / N ), where S is the speedup, and N is the number of processors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f03cf2-1136-4dcf-b52b-333dc39dddfa",
   "metadata": {},
   "source": [
    "#### Gustafson's Law: \n",
    "\n",
    "John Gustafson, in a technical note in 1981, argued that there were problems with Amdahl’s law. Gustafson law assumes that, on a sequential machine, there is a fixed sequential component (s) and a component that can be executed in parallel (p), where s + p = 1. When the program scale to N processors, s remains the same, whereas p is performed on all N processors. So, the scaled speedup according to Gustafson's Law is: \n",
    "\n",
    "**Scaled Speedup = s + (p * N), where s is the sequential component, p is the parallel comppnent, and N is the number of processors**\n",
    "\n",
    "Overall, both Amdahl's Law and Gustafson's Law are good approximations for the limitations of parallel computing, and have their place. It depends on the problem you are looking at on which law to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b605b0-27ea-4987-9315-d531e9a41f4b",
   "metadata": {},
   "source": [
    "#### **Amdahl's Law Question #1: Compute the following value:**\n",
    "\n",
    "You have a program where reading the input and producing the output takes 5 seconds.    The complete sequential version of your code takes 2 minutes to execute.    According to Amdahl's law, what is the maximum speedup that you could achieve on this code using 10 processors, assuming that reading the input and producing the output cannot be run in parallel?\n",
    "\n",
    "Run the code below to see the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93b4a3-2f6d-48c2-8498-4ff87c4fddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "double parallel_time = 120;\n",
    "double sequential_time = 5;\n",
    "int num_of_processors = 10;\n",
    "double speedup = sequential_time / parallel_time;\n",
    "double efficiency = speedup / num_of_processors;\n",
    "double max_speedup = 1 / ( speedup + (1 - speedup) / num_of_processors );\n",
    "printf(\"Answer: Speedup = %.2f\",speedup);\n",
    "printf(\"\\n\");\n",
    "printf(\"Answer: Max Speedup %.2f\",max_speedup);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a522e96-81b7-4103-a312-6f06aaab5c5e",
   "metadata": {},
   "source": [
    "#### **Gustafson's Law Question #1: Compute the following value:**\n",
    "\n",
    "Assume that the sequential portion of your code takes 5% of the time, whereas the rest of the code (which could be run in parallel) takes 95% of the time.   According to Gustafson's law, what is the maximum scaled speedup for this problem on a machine with 100 processors?\n",
    "\n",
    "Run the code below to find the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff876269-bb35-46fd-97c9-98347c6671da",
   "metadata": {},
   "outputs": [],
   "source": [
    "double parallel = .95;\n",
    "double sequential = .05;\n",
    "int num_of_processors = 100;\n",
    "double scaled_speedup = sequential + (parallel * num_of_processors);\n",
    "\n",
    "printf(\"Answer: Scaled Speedup %.2f\", scaled_speedup);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f1dc3-5d8c-4418-9c63-98a14da3e7a1",
   "metadata": {},
   "source": [
    "## **Conclusion:**\n",
    "CS 4000 will provide you with an introduction to distributed, parallel, and web-centric computing. This class will introduce you to some important concepts within the computer science field - including distributed and parallel models of computation, distributed and parallel computer architectures, multi-core designs, potential speed-up, threading, synchronization, and multi-core programming, parallel and distributed algorithms, sockets and client-server based software, web programming, accessing databases across the web, and web-security."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
